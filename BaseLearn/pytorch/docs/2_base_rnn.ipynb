{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 为什么需要RNN \n",
    "- RNN背后的想法是利用顺序的信息\n",
    "- 如果想预测句子中的下一个单词，就需要知道它前面有哪些单词，甚至要看到后面的单词才能给出正确答案。\n",
    "- RNN之所以称为循环，因为它对序列的每个元素都会执行相同的任务，所有的输出取决于先前的计算。\n",
    "- RNN，循环神经网络，期望能够记住前面出现的特征，并依据特征推断后面的结果，而且整体的网络结构不断循环。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN的用途\n",
    "- LSTM\n",
    "- 机器翻译\n",
    "- 语音识别\n",
    "- 生成图像描述\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN的网络结构及原理\n",
    "- 将网络的输出保存在一个记忆单元中，网络的输入会联合记忆单元一起作为输入\n",
    "- [简单介绍](https://blog.csdn.net/zhaojc1995/article/details/80572098)\n",
    "- [英文介绍](https://medium.com/explore-artificial-intelligence/an-introduction-to-recurrent-neural-networks-72c97bf0912)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.RNN\n",
    "- input_size: 输入数据X的特征值数目\n",
    "- hidden_size: 隐藏层的神经元数目\n",
    "- num_layers: rnn的层数，默认是1\n",
    "- bias: 默认true，为false表示神经元不适用bias偏移参数\n",
    "- batch_first: 设置为true,则输入维度第一个维度为batch值，默认为false。默认情况下第一个维度为序列长度，第二个唯独是batch，第三个是特征数目\n",
    "- dropout: 不为空，则表示最后跟一个dropout层抛弃部分数据，抛弃数据的比例由参数设置\n",
    "- bidirectional: 双向RNN，默认为false\n",
    "- nonlinearity: 选用的非线性激活函数，默认为'tanh'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN(20, 50, num_layers=2)\n",
      "torch.Size([100, 32, 20])\n",
      "torch.Size([100, 32, 50]) torch.Size([2, 32, 50])\n",
      "tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1]], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "rnn=nn.RNN(\n",
    "    input_size=20,\n",
    "    hidden_size=50,\n",
    "    num_layers=2,\n",
    "    batch_first=False\n",
    ")\n",
    "print(rnn)\n",
    "input=torch.randn(100,32,20) # batch,最大句子长度,特征数\n",
    "print(input.size())\n",
    "#h_0=torch.randn(2,32,50) # num_layers,batch_size,hidden_size\n",
    "#output,hn=rnn(input,h_0)\n",
    "output,hn=rnn(input)\n",
    "print(output.size(),hn.size())\n",
    "print(output[-1]==hn[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- output[-1]与hn[-1]相等，隐藏层单元就是输出的最后一个单元"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 32, 20])\n",
      "torch.Size([2, 32, 20]) torch.Size([2, 32, 20])\n",
      "<generator object Module.parameters at 0x11cf84150>\n"
     ]
    }
   ],
   "source": [
    "### LSTM\n",
    "lstm=nn.LSTM(10,20,2) # input_size,hidden_size,num_layers\n",
    "input=torch.randn(5,32,10) # input_max_len,batch_size,input_size\n",
    "h0=torch.randn(2,32,20)\n",
    "c0=torch.randn(2,32,20)\n",
    "output,hn=lstm(input,(h0,c0))\n",
    "print(output.size()) #5*3*20\n",
    "print(hn[0].size(),hn[1].size())\n",
    "print(lstm.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.6204,  0.1724, -1.6159], grad_fn=<SelectBackward>)\n",
      "tensor([ 0.6204,  0.1724, -1.6159], grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "### embedding\n",
    "embedding=nn.Embedding(20,3) # 20个词，每个词用三个向量显示\n",
    "input=torch.LongTensor([[1,2,4,5],[4,3,2,9]]) # 取两组，每组四个词\n",
    "a=embedding(input) # 2*4*3\n",
    "print(a[0][1])\n",
    "print(a[1][2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
